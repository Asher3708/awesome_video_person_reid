# 2019   

                             
|No.|Figure   |Title   |features | Results  |Pub.  |Links|
|:-----:|:-----:|:-----:|:-----:|:---:|:---:|:------:|
|1|![ICASSP)](data/1.png)|__All for One: Frame-wise Rank Loss for Improving Video-based Person Re-identification__|Resnet50 + GRU + Rankloss|PRID(Rank1=75.17%) Mars(Rank1=77.27%,mAP=64.76%)|__ICASSP2019__|[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8682292)|
|2|![ITIP](data/2.png)|__Spatial-Temporal Attention-aware Learning for Video-based Person Re-identification__|GoogleNet + STAL|iLIDS-VID(Rank1=82.8%) PRID(Rank1=92.7%) Mars(Rank1=82.2%,mAP=73.5%)|__ITIP2019__|[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8675957)|
|3|![Access](data/3.png)|__Joint Attentive Spatial-Temporal Feature Aggregation for Video-Based Person Re-Identification__|FCN + attention|iLIDS-VID(Rank1=76%) PRID(Rank1=97.4%) Mars(Rank1=89.3%,mAP=74.9%)|__IEEE Access__|[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8675282)|
|4|![Access](data/4.png)|__k-Reciprocal Harmonious Attention Network for Video-Based Person Re-Identification__|Resnet50 + Attention|iLIDS-VID(Rank1=80.3%) PRID(Rank1=90.0%) Mars(Rank1=84.9%,mAp=76.7%)|__IEEE Access__|[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8643936)|
|5|![arixv](data/5.png)|__Intra-clip Aggregation for Video Person Re-identification__|Resnet50 + Synchronized Transformation (ST) and Intra-clip Aggregation (ICA)|iLIDS-VID(Rank1=88.7%) Mars(Rank1=86.0%,mAP=80.8%)|__Arxiv 2019__|[paper](https://arxiv.org/abs/1905.01722.pdf)|
|6|![arixv](data/6.png)|__Video-based Person Re-identification with Two-stream Convolutional Network and Co-attentive Snippet Embedding__|Resnet50 + Attention + Pose and Optical map|iLIDS-VID(Rank1=88.7%) PRID(Rank1=94.4%)|__Arxiv 2019__|[paper](https://arxiv.org/pdf/1905.11862.pdf)|
|7|![cvpr2019](data/7.png)|__Attribute-Driven Feature Disentangling and Temporal Aggregation for Video Person Re-Identification__|Resnet50 + attribute learning|iLIDS-VID(Rank1=86.3%) PRID(Rank1=93.9%) Mars(Rank1=82.6%,mAP=71.2%)|__CVPR2019__|[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhao_Attribute-Driven_Feature_Disentangling_and_Temporal_Aggregation_for_Video_Person_Re-Identification_CVPR_2019_paper.pdf)|
|8|![cvpr2019](data/8.png)|__VRSTC: Occlusion-Free Video Person Re-Identification__|Resnet50 + Attention + GAN|iLIDS-VID(Rank1=83.4%) Mars(Rank1=88.5%,mAP=82.3%) DukeMTMC(Rank1=95.0%,mAP=93.5%)|__CVPR2019__|[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Hou_VRSTC_Occlusion-Free_Video_Person_Re-Identification_CVPR_2019_paper.pdf)|